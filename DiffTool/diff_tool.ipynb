{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import builtins\n",
    "import json\n",
    "from types import FunctionType\n",
    "\n",
    "from PaladinEngine.archive.archive import Archive\n",
    "from PaladinUI.paladin_server.paladin_server import PaladinServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_FILE_PATH = \"diff_tool_input.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_archive_from_csv(csv_path):\n",
    "    dataframe = load_csv_to_dataframe(csv_path)\n",
    "    archive_from_csv = Archive()\n",
    "    rows = dataframe.to_records()\n",
    "    for row in rows: #TODO: look for a builtin function instead of loop?\n",
    "        record_key, record_value = create_record_key_value(row)\n",
    "        archive_from_csv.store_with_original_time(record_key, record_value)\n",
    "    return archive_from_csv\n",
    "\n",
    "def load_csv_to_dataframe(csv_path):\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    dataframe = dataframe.fillna('')\n",
    "    return dataframe\n",
    "\n",
    "def create_record_key_value(row):\n",
    "    record_key = Archive.Record.RecordKey(int(row.container_id), row.field, row.stub_name)\n",
    "\n",
    "    if row.rtype == 'function':\n",
    "        value_of_record = row.value\n",
    "        type_of_record = FunctionType\n",
    "    elif row.rtype == 'list':\n",
    "        value_of_record = ast.literal_eval(row.value)\n",
    "        type_of_record = list\n",
    "    elif row.rtype == 'bool':\n",
    "        value_of_record = True if row.value == 'True' else False\n",
    "        type_of_record = bool\n",
    "    else:\n",
    "        value_of_record = getattr(builtins, row.rtype)(row.value)\n",
    "        type_of_record = type(value_of_record)\n",
    "\n",
    "    record_value = Archive.Record.RecordValue(\n",
    "        record_key, type_of_record, value_of_record, row.expression,\n",
    "        int(row.line_no), int(row.time), row.extra\n",
    "    )\n",
    "    return record_key, record_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_query_result_to_presentable_table(query_result):\n",
    "    result = query_result['result']['query']\n",
    "    # Change shape so time ranges are rows instead of columns\n",
    "    result_df = pd.read_json(result).transpose()\n",
    "    # Extract only needed columns and rename them\n",
    "    result_df.reset_index(inplace=True)\n",
    "    times_column_name = 'Time Range'\n",
    "    result_df = result_df.rename(columns={'index': times_column_name})\n",
    "    first_column = result_df[0]\n",
    "    first_value = first_column.iat[0]\n",
    "    queries_from_result = list(first_value.keys())\n",
    "    for query_from_result in queries_from_result:\n",
    "        result_df[query_from_result] = first_column.apply(lambda d: d.get(query_from_result))\n",
    "    subset_columns = [times_column_name] + queries_from_result\n",
    "    minimal_df = result_df[subset_columns]\n",
    "    return minimal_df, queries_from_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def get_parameter_matches_with_previous_query(parameters, csv_path):\n",
    "#     parameter_matches = {}\n",
    "#     for parameter in parameters:\n",
    "#         parameter_matches[parameter] = input(f\"Match {parameter} in {csv_path}: \")\n",
    "#     return parameter_matches\n",
    "#\n",
    "# def replace_matched_parameters(previous_query, parameter_matches):\n",
    "#     matched_query = previous_query\n",
    "#     for source_parameter, dest_parameter in parameter_matches.items():\n",
    "#         matched_query = matched_query.replace(source_parameter, dest_parameter)\n",
    "#     return matched_query\n",
    "#\n",
    "# def convert_parameter_to_queryable(parameter):\n",
    "#     location_separator = '@'\n",
    "#     if location_separator in parameter:\n",
    "#         parameter_name, parameter_location = parameter.split(location_separator)\n",
    "#         queryable = f\"[[{parameter_name}]]@{parameter_location}\"\n",
    "#     else:\n",
    "#         queryable = f\"[[{parameter}]]\"\n",
    "#     return queryable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataframes_from_csvs(csv_files):\n",
    "    archives = []\n",
    "    dataframes = []\n",
    "\n",
    "    for csv_file_info in csv_files:\n",
    "        csv_archive = create_archive_from_csv(csv_file_info[\"csv_file_path\"])\n",
    "        archives.append(csv_archive)\n",
    "        server = PaladinServer.create('', csv_archive)\n",
    "        raw_result = server.query(csv_file_info[\"query\"], csv_file_info[\"start_time\"], csv_file_info[\"end_time\"], csv_file_info[\"line_no\"])\n",
    "        presentable_df, parameters = convert_query_result_to_presentable_table(raw_result)\n",
    "        print(presentable_df)\n",
    "        dataframes.append(presentable_df)\n",
    "\n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    with open(INPUT_FILE_PATH, 'r') as fileobj:\n",
    "        data = json.load(fileobj)\n",
    "    csv_files = data[\"csv_files\"]\n",
    "    dataframes = create_dataframes_from_csvs(csv_files)\n",
    "\n",
    "    result_merge_condition = data[\"result_merge_condition\"]\n",
    "    result_rows = pd.merge(\n",
    "        dataframes[0], dataframes[1],\n",
    "        how=\"inner\",\n",
    "        left_on=result_merge_condition[\"left_on\"], right_on=result_merge_condition[\"right_on\"],\n",
    "        indicator=True\n",
    "    )\n",
    "    result_rows = result_rows[~((result_rows['result@12'].isna()) & (result_rows['result@16'].isna()))]\n",
    "    # print(result_rows)\n",
    "\n",
    "    iteration_merge_condition = data[\"iteration_merge_condition\"]\n",
    "    iteration_rows = pd.merge(\n",
    "        dataframes[0], dataframes[1],\n",
    "        how=\"outer\",\n",
    "        left_on=iteration_merge_condition[\"left_on\"], right_on=iteration_merge_condition[\"right_on\"],\n",
    "        indicator=True\n",
    "    )\n",
    "    iteration_rows = iteration_rows[((iteration_rows['result@12'].isna()) & (iteration_rows['result@16'].isna()))]\n",
    "    # print(iteration_rows)\n",
    "\n",
    "    merged = pd.concat([iteration_rows, result_rows], ignore_index=True)\n",
    "    print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time Range   i@4  number@11 result@12\n",
      "0      (0, 1)   NaN        NaN      None\n",
      "1      (2, 6)   NaN       13.0      None\n",
      "2      (7, 7)   2.0       13.0      None\n",
      "3      (8, 8)   3.0       13.0      None\n",
      "4      (9, 9)   4.0       13.0      None\n",
      "5    (10, 10)   5.0       13.0      None\n",
      "6    (11, 11)   6.0       13.0      None\n",
      "7    (12, 12)   7.0       13.0      None\n",
      "8    (13, 13)   8.0       13.0      None\n",
      "9    (14, 14)   9.0       13.0      None\n",
      "10   (15, 15)  10.0       13.0      None\n",
      "11   (16, 16)  11.0       13.0      None\n",
      "12   (17, 18)  12.0       13.0      None\n",
      "13  (19, 500)  12.0       13.0      True\n",
      "  Time Range  i@8  number@15 result@16\n",
      "0     (0, 1)  NaN        NaN      None\n",
      "1     (2, 8)  NaN       13.0      None\n",
      "2     (9, 9)  2.0       13.0      None\n",
      "3   (10, 11)  3.0       13.0      None\n",
      "4  (12, 500)  3.0       13.0      True\n",
      "   Time Range_x   i@4  number@11 result@12 Time Range_y  i@8  number@15  \\\n",
      "0        (0, 1)   NaN        NaN      None       (0, 1)  NaN        NaN   \n",
      "1        (2, 6)   NaN       13.0      None       (2, 8)  NaN       13.0   \n",
      "2        (7, 7)   2.0       13.0      None       (9, 9)  2.0       13.0   \n",
      "3        (8, 8)   3.0       13.0      None     (10, 11)  3.0       13.0   \n",
      "4        (9, 9)   4.0       13.0      None          NaN  NaN        NaN   \n",
      "5      (10, 10)   5.0       13.0      None          NaN  NaN        NaN   \n",
      "6      (11, 11)   6.0       13.0      None          NaN  NaN        NaN   \n",
      "7      (12, 12)   7.0       13.0      None          NaN  NaN        NaN   \n",
      "8      (13, 13)   8.0       13.0      None          NaN  NaN        NaN   \n",
      "9      (14, 14)   9.0       13.0      None          NaN  NaN        NaN   \n",
      "10     (15, 15)  10.0       13.0      None          NaN  NaN        NaN   \n",
      "11     (16, 16)  11.0       13.0      None          NaN  NaN        NaN   \n",
      "12     (17, 18)  12.0       13.0      None          NaN  NaN        NaN   \n",
      "13    (19, 500)  12.0       13.0      True    (12, 500)  3.0       13.0   \n",
      "\n",
      "   result@16     _merge  \n",
      "0       None       both  \n",
      "1       None       both  \n",
      "2       None       both  \n",
      "3       None       both  \n",
      "4        NaN  left_only  \n",
      "5        NaN  left_only  \n",
      "6        NaN  left_only  \n",
      "7        NaN  left_only  \n",
      "8        NaN  left_only  \n",
      "9        NaN  left_only  \n",
      "10       NaN  left_only  \n",
      "11       NaN  left_only  \n",
      "12       NaN  left_only  \n",
      "13      True       both  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nRun:\\npython C:\\\\Avital\\\\Github\\\\paladin_engine\\\\PaladinUI\\\\paladin_cli\\\\paladin_cli.py --run --output-file output.py --csv DiffTool\\\\is_prime_naive.csv --run-debug-server True --port 1234\\nC:\\\\Avital\\\\Github\\\\paladin_engine\\\\PaladinEngine\\tests\\test_resources\\\\examples\\\\is_prime\\\\is_prime_naive.py\\n\\n#TODO:\\n1) keys id: update the ctor\\n2) time: 0 is converted to [1,5] (line_no==85)\\n3) set: not supported\\n\\n#TODO: 28.11\\n1) keys: id: update the ctor? ask Oren why it is needed id(v.key)\\n2) store: write our function which doesn't change time\\n3) represent: call represent asap (maybe in ctor) instead of in to_table\\n4) paladin_server.py: debug_info/query/ - check that the Archive is OK\\n\\n#Questions:\\n1) Will we always have exactly 2 tables to compare, or can there be more? A: let's start with 2, but can be more\\n2) How exactly are we supposed to connect each two tables? For example in is_prime,\\nshould we just match the 13 rows of 'square' to the first 13 rows of 'naive'?\\n3) User input - how? Using python's input(), or maybe read from file?\\nMaybe should depend on the number of parameters in the query\\nA: use files\\n\\n#TODO: 06.12\\nV 1) not interactive, use files\\nV 2) join two tables using merge/join pandas\\nV 3) we get as input the query for creating the match between both tables (total_slices_1 == total_slices_2)\\n4) represent: create object and check\\n5) change set to list\\n6) create more examples, more complex than is_prime\\n\""
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run:\n",
    "python C:\\Avital\\Github\\paladin_engine\\PaladinUI\\paladin_cli\\paladin_cli.py --run --output-file output.py --csv DiffTool\\is_prime_naive.csv --run-debug-server True --port 1234\n",
    "C:\\Avital\\Github\\paladin_engine\\PaladinEngine\\tests\\test_resources\\examples\\is_prime\\is_prime_naive.py\n",
    "\n",
    "#TODO:\n",
    "1) keys id: update the ctor\n",
    "2) time: 0 is converted to [1,5] (line_no==85)\n",
    "3) set: not supported\n",
    "\n",
    "#TODO: 28.11\n",
    "1) keys: id: update the ctor? ask Oren why it is needed id(v.key)\n",
    "2) store: write our function which doesn't change time\n",
    "3) represent: call represent asap (maybe in ctor) instead of in to_table\n",
    "4) paladin_server.py: debug_info/query/ - check that the Archive is OK\n",
    "\n",
    "#Questions:\n",
    "1) Will we always have exactly 2 tables to compare, or can there be more? A: let's start with 2, but can be more\n",
    "2) How exactly are we supposed to connect each two tables? For example in is_prime,\n",
    "should we just match the 13 rows of 'square' to the first 13 rows of 'naive'?\n",
    "3) User input - how? Using python's input(), or maybe read from file?\n",
    "Maybe should depend on the number of parameters in the query\n",
    "A: use files\n",
    "\n",
    "#TODO: 06.12\n",
    "1) not interactive, use files\n",
    "2) join two tables using merge/join pandas\n",
    "3) we get as input the query for creating the match between both tables (total_slices_1 == total_slices_2)\n",
    "4) represent: create object and check\n",
    "5) change set to list\n",
    "6) create more examples, more complex than is_prime\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}