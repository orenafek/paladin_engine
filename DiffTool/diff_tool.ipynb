{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import builtins\n",
    "import json\n",
    "from types import FunctionType\n",
    "\n",
    "from PaladinEngine.archive.archive import Archive\n",
    "from PaladinUI.paladin_server.paladin_server import PaladinServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_FILE_PATH = \"diff_tool_input.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_archive_from_csv(csv_path):\n",
    "    dataframe = load_csv_to_dataframe(csv_path)\n",
    "    archive_from_csv = Archive()\n",
    "    rows = dataframe.to_records()\n",
    "    for row in rows:\n",
    "        record_key, record_value = create_record_key_value(row)\n",
    "        archive_from_csv.store_with_original_time(record_key, record_value)\n",
    "    return archive_from_csv\n",
    "\n",
    "def load_csv_to_dataframe(csv_path):\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    dataframe = dataframe.fillna('')\n",
    "    return dataframe\n",
    "\n",
    "def create_record_key_value(row):\n",
    "    row_field = int(row.field) if row.field.isnumeric() else row.field\n",
    "    record_key = Archive.Record.RecordKey(\n",
    "        int(row.container_id), row_field, row.stub_name, Archive.Record.StoreKind[row.kind]\n",
    "    )\n",
    "\n",
    "    if record_key.stub_name == \"__AS__\" and row.rtype in ['list', 'dict', 'tuple', 'set']:\n",
    "        value_of_record = ast.literal_eval(row.value)\n",
    "        type_of_record = row.rtype\n",
    "    elif row.rtype == 'function':\n",
    "        value_of_record = row.value\n",
    "        type_of_record = FunctionType\n",
    "    elif row.rtype == 'list':\n",
    "        value_of_record = ast.literal_eval(row.value)\n",
    "        type_of_record = list\n",
    "    elif row.rtype == 'bool':\n",
    "        value_of_record = True if row.value == 'True' else False\n",
    "        type_of_record = bool\n",
    "    elif row.rtype == 'dict':\n",
    "        value_of_record = ast.literal_eval(row.value)\n",
    "        type_of_record = dict #TODO: add same for tuple and set\n",
    "    else:\n",
    "        value_of_record = getattr(builtins, row.rtype)(row.value)\n",
    "        type_of_record = type(value_of_record)\n",
    "\n",
    "    record_value = Archive.Record.RecordValue(\n",
    "        record_key, type_of_record, value_of_record, row.expression,\n",
    "        int(row.line_no), int(row.time), row.extra\n",
    "    )\n",
    "    return record_key, record_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def build_object_from_archive(archive_from_csv, record_value):\n",
    "#     print(f\"v.rtype: {record_value.rtype} | v.value: {record_value.value}\")\n",
    "#     print(\"NEW CODE2\")\n",
    "#     # import pdb; pdb.set_trace()\n",
    "#     value_of_record = archive_from_csv.build_object(record_value.value, record_value.time)\n",
    "#     record_value.value = value_of_record\n",
    "#     record_value.rtype = type(value_of_record)\n",
    "#     print(f\"record_value.rtype: {record_value.rtype} | value_of_record: {value_of_record}\")\n",
    "#     return record_value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_query_result_to_presentable_table(query_result):\n",
    "    print(query_result)\n",
    "    result = query_result['result']['query']\n",
    "    if result == '\"\"':\n",
    "        raise Exception(\"Empty query result!\")\n",
    "    json_data = json.loads(result)\n",
    "    json_data.pop('keys')\n",
    "    result_df = pd.DataFrame.from_dict(json_data, orient=\"index\")\n",
    "    result_df.reset_index(inplace=True)\n",
    "    times_column_name = 'Time Range'\n",
    "    result_df = result_df.rename(columns={'index': times_column_name})\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def get_parameter_matches_with_previous_query(parameters, csv_path):\n",
    "#     parameter_matches = {}\n",
    "#     for parameter in parameters:\n",
    "#         parameter_matches[parameter] = input(f\"Match {parameter} in {csv_path}: \")\n",
    "#     return parameter_matches\n",
    "#\n",
    "# def replace_matched_parameters(previous_query, parameter_matches):\n",
    "#     matched_query = previous_query\n",
    "#     for source_parameter, dest_parameter in parameter_matches.items():\n",
    "#         matched_query = matched_query.replace(source_parameter, dest_parameter)\n",
    "#     return matched_query\n",
    "#\n",
    "# def convert_parameter_to_queryable(parameter):\n",
    "#     location_separator = '@'\n",
    "#     if location_separator in parameter:\n",
    "#         parameter_name, parameter_location = parameter.split(location_separator)\n",
    "#         queryable = f\"[[{parameter_name}]]@{parameter_location}\"\n",
    "#     else:\n",
    "#         queryable = f\"[[{parameter}]]\"\n",
    "#     return queryable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataframes_from_csvs(csv_files):\n",
    "    archives = []\n",
    "    dataframes = []\n",
    "\n",
    "    for csv_file_info in csv_files:\n",
    "        csv_archive = create_archive_from_csv(csv_file_info[\"csv_file_path\"])\n",
    "        archives.append(csv_archive)\n",
    "        server = PaladinServer.create('', csv_archive)\n",
    "        raw_result = server.query(csv_file_info[\"query\"], csv_file_info[\"start_time\"], csv_file_info[\"end_time\"])\n",
    "        presentable_df = convert_query_result_to_presentable_table(raw_result)\n",
    "        print(presentable_df)\n",
    "        dataframes.append(presentable_df)\n",
    "\n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    with open(INPUT_FILE_PATH, 'r') as fileobj:\n",
    "        data = json.load(fileobj)\n",
    "    csv_files = data[\"csv_files\"]\n",
    "    dataframes = create_dataframes_from_csvs(csv_files)\n",
    "\n",
    "    result_merge_condition = data[\"result_merge_condition\"]\n",
    "    result_merge_condition_left = result_merge_condition[\"left_on\"]\n",
    "    if len(result_merge_condition_left) == 1:\n",
    "        result_merge_condition_left = result_merge_condition_left[0]\n",
    "    result_merge_condition_right = result_merge_condition[\"right_on\"]\n",
    "    if len(result_merge_condition_right) == 1:\n",
    "        result_merge_condition_right = result_merge_condition_right[0]\n",
    "\n",
    "    result_rows = pd.merge(\n",
    "        dataframes[0], dataframes[1],\n",
    "        how=\"inner\",\n",
    "        left_on=result_merge_condition_left, right_on=result_merge_condition_right,\n",
    "        indicator=True\n",
    "    )\n",
    "    result_rows = result_rows[~((result_rows[result_merge_condition_left].isna()) & (result_rows[result_merge_condition_right].isna()))]\n",
    "    print(result_rows)\n",
    "\n",
    "    iteration_merge_condition = data[\"iteration_merge_condition\"]\n",
    "    iteration_rows = pd.merge(\n",
    "        dataframes[0], dataframes[1],\n",
    "        how=\"outer\",\n",
    "        left_on=iteration_merge_condition[\"left_on\"], right_on=iteration_merge_condition[\"right_on\"],\n",
    "        indicator=True\n",
    "    )\n",
    "    iteration_rows = iteration_rows[((iteration_rows[result_merge_condition_left].isna()) & (iteration_rows[result_merge_condition_right].isna()))]\n",
    "    print(iteration_rows)\n",
    "\n",
    "    merged = pd.concat([iteration_rows, result_rows], ignore_index=True)\n",
    "    print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run:\n",
    "python C:\\Avital\\Github\\paladin_engine\\PaladinUI\\paladin_cli\\paladin_cli.py --run --output-file output.py --csv DiffTool\\is_prime_naive.csv --run-debug-server True --port 1234\n",
    "C:\\Avital\\Github\\paladin_engine\\PaladinEngine\\tests\\test_resources\\examples\\is_prime\\is_prime_naive.py\n",
    "\n",
    "#TODO:\n",
    "1) keys id: update the ctor\n",
    "2) time: 0 is converted to [1,5] (line_no==85)\n",
    "3) set: not supported\n",
    "\n",
    "#TODO: 28.11\n",
    "1) keys: id: update the ctor? ask Oren why it is needed id(v.key)\n",
    "2) store: write our function which doesn't change time\n",
    "3) represent: call represent asap (maybe in ctor) instead of in to_table\n",
    "4) paladin_server.py: debug_info/query/ - check that the Archive is OK\n",
    "\n",
    "#Questions:\n",
    "1) Will we always have exactly 2 tables to compare, or can there be more? A: let's start with 2, but can be more\n",
    "2) How exactly are we supposed to connect each two tables? For example in is_prime,\n",
    "should we just match the 13 rows of 'square' to the first 13 rows of 'naive'?\n",
    "3) User input - how? Using python's input(), or maybe read from file?\n",
    "Maybe should depend on the number of parameters in the query\n",
    "A: use files\n",
    "\n",
    "#TODO: 06.12\n",
    "1) not interactive, use files\n",
    "2) join two tables using merge/join pandas\n",
    "3) we get as input the query for creating the match between both tables (total_slices_1 == total_slices_2)\n",
    "4) represent: create object and check\n",
    "5) change set to list\n",
    "6) create more examples, more complex than is_prime\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}