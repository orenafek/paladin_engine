{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import builtins\n",
    "import os\n",
    "from types import FunctionType\n",
    "\n",
    "from PaladinEngine.archive.archive import Archive\n",
    "from PaladinUI.paladin_cli.paladin_cli import dump_to_csv\n",
    "from PaladinUI.paladin_server.paladin_server import PaladinServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "# CSV_FILE_PATHS = [\"caterpillar_output_sdn.csv\", \"caterpillar_output_sn.csv\"]\n",
    "# CSV_FILE_PATHS = [\"DiffTool/is_prime_naive.csv\", \"DiffTool/is_prime_square.csv\"]\n",
    "CSV_FILE_PATHS = [\"is_prime_naive.csv\", \"is_prime_square.csv\"]\n",
    "# CSV_FILE_PATHS = [\"is_prime_naive.csv\"]\n",
    "TEST_CSV_FILE_PATH_TEMPLATE = \"DiffTool/test_{}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [],
   "source": [
    "def create_archive_from_csv(csv_path):\n",
    "    dataframe = load_csv_to_dataframe(csv_path)\n",
    "    archive_from_csv = Archive()\n",
    "    rows = dataframe.to_records()\n",
    "    for row in rows: #TODO: look for a builtin function instead of loop?\n",
    "        record_key, record_value = create_record_key_value(row)\n",
    "        archive_from_csv.store_with_original_time(record_key, record_value)\n",
    "    return archive_from_csv\n",
    "\n",
    "def load_csv_to_dataframe(csv_path):\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    dataframe = dataframe.fillna('')\n",
    "    return dataframe\n",
    "\n",
    "def create_record_key_value(row):\n",
    "    record_key = Archive.Record.RecordKey(int(row.container_id), row.field, row.stub_name)\n",
    "\n",
    "    if row.rtype == 'function':\n",
    "        value_of_record = row.value\n",
    "        type_of_record = FunctionType\n",
    "    elif row.rtype == 'list':\n",
    "        value_of_record = ast.literal_eval(row.value)\n",
    "        type_of_record = list\n",
    "    else:\n",
    "        value_of_record = getattr(builtins, row.rtype)(row.value)\n",
    "        type_of_record = type(value_of_record)\n",
    "\n",
    "    record_value = Archive.Record.RecordValue(\n",
    "        record_key, type_of_record, value_of_record, row.expression,\n",
    "        int(row.line_no), int(row.time), row.extra\n",
    "    )\n",
    "    return record_key, record_value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [],
   "source": [
    "def convert_query_result_to_presentable_table(query_result):\n",
    "    result = query_result['result']['query']\n",
    "    # Change shape so time ranges are rows instead of columns\n",
    "    result_df = pd.read_json(result).transpose()\n",
    "    # Extract only needed columns and rename them\n",
    "    result_df.reset_index(inplace=True)\n",
    "    times_column_name = 'Time Range'\n",
    "    result_df = result_df.rename(columns={'index': times_column_name})\n",
    "    first_column = result_df[0]\n",
    "    first_value = first_column.iat[0]\n",
    "    queries_from_result = list(first_value.keys())\n",
    "    for query_from_result in queries_from_result:\n",
    "        result_df[query_from_result] = first_column.apply(lambda d: d.get(query_from_result))\n",
    "    subset_columns = [times_column_name] + queries_from_result\n",
    "    minimal_df = result_df[subset_columns]\n",
    "    return minimal_df, queries_from_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [],
   "source": [
    "def get_parameter_matches_with_previous_query(parameters, csv_path):\n",
    "    parameter_matches = {}\n",
    "    for parameter in parameters:\n",
    "        parameter_matches[parameter] = input(f\"Match {parameter} in {csv_path}: \")\n",
    "    return parameter_matches\n",
    "\n",
    "def replace_matched_parameters(previous_query, parameter_matches):\n",
    "    matched_query = previous_query\n",
    "    for source_parameter, dest_parameter in parameter_matches.items():\n",
    "        matched_query = matched_query.replace(source_parameter, dest_parameter)\n",
    "    return matched_query\n",
    "\n",
    "def convert_parameter_to_queryable(parameter):\n",
    "    location_separator = '@'\n",
    "    if location_separator in parameter:\n",
    "        parameter_name, parameter_location = parameter.split(location_separator)\n",
    "        queryable = f\"[[{parameter_name}]]@{parameter_location}\"\n",
    "    else:\n",
    "        queryable = f\"[[{parameter}]]\"\n",
    "    return queryable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Time Range    i@4  number@11\n",
      "0        (0, 1)    NaN        NaN\n",
      "1        (2, 6)    NaN      173.0\n",
      "2        (7, 7)    2.0      173.0\n",
      "3        (8, 8)    3.0      173.0\n",
      "4        (9, 9)    4.0      173.0\n",
      "..          ...    ...        ...\n",
      "168  (173, 173)  168.0      173.0\n",
      "169  (174, 174)  169.0      173.0\n",
      "170  (175, 175)  170.0      173.0\n",
      "171  (176, 176)  171.0      173.0\n",
      "172  (177, 500)  172.0      173.0\n",
      "\n",
      "[173 rows x 3 columns]\n",
      "   Time Range   i@8  number@15\n",
      "0      (0, 1)   NaN        NaN\n",
      "1      (2, 8)   NaN      173.0\n",
      "2      (9, 9)   2.0      173.0\n",
      "3    (10, 10)   3.0      173.0\n",
      "4    (11, 11)   4.0      173.0\n",
      "5    (12, 12)   5.0      173.0\n",
      "6    (13, 13)   6.0      173.0\n",
      "7    (14, 14)   7.0      173.0\n",
      "8    (15, 15)   8.0      173.0\n",
      "9    (16, 16)   9.0      173.0\n",
      "10   (17, 17)  10.0      173.0\n",
      "11   (18, 18)  11.0      173.0\n",
      "12   (19, 19)  12.0      173.0\n",
      "13  (20, 500)  13.0      173.0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load the csv file into a DataFrame object\n",
    "    archives = []\n",
    "    initial_query = input(\"Enter your query: \")\n",
    "    initial_parameters = []\n",
    "    for index, csv_path in enumerate(CSV_FILE_PATHS):\n",
    "        csv_archive = create_archive_from_csv(csv_path)\n",
    "        archives.append(csv_archive)\n",
    "\n",
    "        # Run a query using the archive created from the csv file\n",
    "        server = PaladinServer.create('', csv_archive)\n",
    "\n",
    "        is_initial_query = index == 0\n",
    "        matched_query = initial_query\n",
    "        if not is_initial_query:\n",
    "            parameter_matches = get_parameter_matches_with_previous_query(initial_parameters, csv_path)\n",
    "            matched_query = replace_matched_parameters(initial_query, parameter_matches)\n",
    "        # raw_result = server.query('[[i]]@4', 0, 500, 0)\n",
    "        # raw_result = server.query('Union([[i]]@4, [[number]]@11)', 0, 500, 0)\n",
    "        raw_result = server.query(matched_query, 0, 500, 0)\n",
    "\n",
    "        # Convert the result to the required form\n",
    "        presentable_df, parameters = convert_query_result_to_presentable_table(raw_result)\n",
    "        if is_initial_query:\n",
    "            initial_parameters = [convert_parameter_to_queryable(parameter) for parameter in parameters]\n",
    "        print(presentable_df)\n",
    "        # dump_to_csv(csv_archive, TEST_CSV_FILE_PATH_TEMPLATE.format(os.path.basename(csv_path))) #TODO: remove later\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nRun:\\npython C:\\\\Avital\\\\Github\\\\paladin_engine\\\\PaladinUI\\\\paladin_cli\\\\paladin_cli.py --run --output-file output.py --csv DiffTool\\\\is_prime_naive.csv --run-debug-server True --port 1234\\nC:\\\\Avital\\\\Github\\\\paladin_engine\\\\PaladinEngine\\tests\\test_resources\\\\examples\\\\is_prime\\\\is_prime_naive.py\\n\\n#TODO:\\n1) keys id: update the ctor\\n2) time: 0 is converted to [1,5] (line_no==85)\\n3) set: not supported\\n\\n#TODO: 28.11\\n1) keys: id: update the ctor? ask Oren why it is needed id(v.key)\\n2) store: write our function which doesn't change time\\n3) represent: call represent asap (maybe in ctor) instead of in to_table\\n4) paladin_server.py: debug_info/query/ - check that the Archive is OK\\n\\n#Questions:\\n1) Will we always have exactly 2 tables to compare, or can there be more?\\n2) How exactly are we supposed to connect each two tables? For example in is_prime,\\nshould we just match the 13 rows of 'square' to the first 13 rows of 'naive'?\\n3) User input - how? Using python's input(), or maybe read from file?\\nMaybe should depend on the number of parameters in the query\\n4)\\n\""
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run:\n",
    "python C:\\Avital\\Github\\paladin_engine\\PaladinUI\\paladin_cli\\paladin_cli.py --run --output-file output.py --csv DiffTool\\is_prime_naive.csv --run-debug-server True --port 1234\n",
    "C:\\Avital\\Github\\paladin_engine\\PaladinEngine\\tests\\test_resources\\examples\\is_prime\\is_prime_naive.py\n",
    "\n",
    "#TODO:\n",
    "1) keys id: update the ctor\n",
    "2) time: 0 is converted to [1,5] (line_no==85)\n",
    "3) set: not supported\n",
    "\n",
    "#TODO: 28.11\n",
    "1) keys: id: update the ctor? ask Oren why it is needed id(v.key)\n",
    "2) store: write our function which doesn't change time\n",
    "3) represent: call represent asap (maybe in ctor) instead of in to_table\n",
    "4) paladin_server.py: debug_info/query/ - check that the Archive is OK\n",
    "\n",
    "#Questions:\n",
    "1) Will we always have exactly 2 tables to compare, or can there be more?\n",
    "2) How exactly are we supposed to connect each two tables? For example in is_prime,\n",
    "should we just match the 13 rows of 'square' to the first 13 rows of 'naive'?\n",
    "3) User input - how? Using python's input(), or maybe read from file?\n",
    "Maybe should depend on the number of parameters in the query\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}